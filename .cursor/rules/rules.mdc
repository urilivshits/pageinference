---
description: Guidelines for every query.
globs: 
alwaysApply: true
---
# Cursor AI Guidelines
<!-- Guidelines for every query. -->
This document serves as a guide for AI coding assistance.

## Naming Conventions
- Variables: camelCase
- Functions: camelCase
- Classes: PascalCase
- Components: PascalCase
- Constants: UPPER_SNAKE_CASE
- Files: kebab-case

## Code Organization
- Imports: grouped by source (standard library, third-party, local)
- Component structure: props, state, effects, handlers, render
- Max file length: 300 lines (prefer composition over large files)
- Simplicity: Always prefer simple solutions over complex ones
- Avoid duplication: Check for existing similar code before implementing new functionality
- File scripts: Avoid writing one-off scripts in files when possible
- Cleanliness: Keep the codebase very clean and organized
- Indentation: Use two spaces for indentation in all code files

## Implementation Strategy
- Change scope: Only make changes that are requested or well understood and related to the task
- Impact assessment: Always consider what other methods and areas of code might be affected by changes
- Fix approach: Exhaust existing implementation options before introducing new patterns or technology
- Environment awareness: Code should account for different environments: dev, test, and prod
- Mocking policy: Use mocking data only for tests, never for dev or prod environments
- Env file: Never overwrite .env files without explicit permission

## Task Management

### Process
1. Convert high-level tasks and user queries to detailed step-by-step instructions
2. Create detailed markdown numbered list of tasks in `rootFolder/.user/tasks.md`
3. Include checkboxes for each substep (default unchecked)
4. Parse every user query to automatically generate tasks and subtasks
5. Record all updates, changes, and tasks in `rootFolder/.user/tasks.md`
6. Review tasks at the end of every response and mark completed items
7. Reopen resolved tasks if bugs are reported later
8. Check for unmarked tasks at the beginning of every response

### Focus and Scope
- Focus only on areas of code relevant to the task
- Do not touch code that is unrelated to the task
- Avoid making major changes to patterns and architecture unless explicitly instructed

## File Maintenance

### CRITICAL: Required Updates for EVERY Response
- **MANDATORY:** Review and update `rootFolder/.user/tasks.md` and `rootFolder/.user/queries.md` at the beginning of EVERY user query (these files already exist)
- **MANDATORY:** Update `rootFolder/.user/queries.md` IMMEDIATELY when receiving ANY user query, without exception
- **MANDATORY:** Update `rootFolder/.user/tasks.md` TWICE during each interaction:
  1. At the BEGINNING: Add new tasks derived from user's query
  2. At the END: Mark completed tasks and review progress
- Consider EVERY user query, no matter how small, as a task that requires tracking
- Even questions without code changes must be logged in both files
- Never skip these updates for ANY reason - they are highest priority
- Apply all other rules to code changes and new files
- NEVER include `` tags in any of the following files: `temp-rules.md`, `context.md`, `queries.md`, or `tasks.md`

### File Artifacts Management
- `temp-rules.md`, `context.md`, `queries.md`, and `tasks.md` are critical system artifacts that must be preserved
- These files should be treated as persistent artifacts across sessions
- Always maintain the integrity and format of these files
- When any changes are made to these files, ensure they are properly saved as artifacts
- If a change is made to any one of these files, review the others to ensure consistency across all artifacts
- **MANDATORY:** When updating any content in `context.md`, `queries.md`, or `tasks.md`, validate that references to related content in the other files remain accurate
- Any modifications to the structure or format of these files must be explicitly approved by the user

### Update Content Requirements
- `rootFolder/.user/tasks.md`: 
  - **MANDATORY:** All new tasks must include detailed substeps with checkboxes
  - **MANDATORY:** All completed steps must be marked with [x] at the end of the response
  - Categorize tasks logically with clear headings
  - Maintain chronological order of tasks
  
- `rootFolder/.user/queries.md`:
  - **MANDATORY:** Record the exact user query text in quotes
  - Maintain chronological order of queries

## Project Progress Report

### CRITICAL: Required for EVERY Response
- **MANDATORY:** Review `rootFolder/.user/context.md` (Project Progress Report) at the beginning of EVERY user query (this file already exists)
- The Project Progress Report contains critical information about the project's evolution
- Use this report to understand what has been built, what technical approaches have been taken, and what issues have been resolved
- This report helps maintain continuity across different sessions and interactions
- **MANDATORY:** Update the Project Progress Report whenever:
  1. New technical approaches or architectural decisions are made
  2. New features are implemented
  3. Bugs are resolved
  4. Any significant changes are made to `queries.md` or `tasks.md` that affect project understanding
- Keep the Project Progress Report organized in exactly three sections:
  1. Technical approaches and architectural decisions
  2. Implemented features
  3. Resolved bugs
- For each new entry in the Project Progress Report:
  - Add a descriptive identifier or short title
  - Provide a clear, concise description of the change or addition
  - Include references to relevant code areas or files
- **MANDATORY:** Summarize any updates made to the Project Progress Report at the end of your response
- If a user query has implications for the project that should be tracked, always update the report
- Never remove information from the Project Progress Report unless explicitly instructed
- Never remove the commented example entries in the Project Progress Report
- Prioritize solutions that align with previously documented technical approaches
- Ensure all artifact files (`context.md`, `queries.md`, and `tasks.md`) remain synchronized with respect to project state

## Tool Usage
- Code modifications: `edit_file`
- Code exploration: `codebase_search`, `read_file`, `list_dir`, `grep_search`, `file_search`
- Run commands: `run_terminal_cmd`
- Web information: `web_search`
- Change history: `diff_history`

## Token Limit Handling
- Monitor token usage throughout long responses
- If approaching token limits during a complex task:
  1. Save current progress in relevant artifact files (`context.md`, `queries.md`, `tasks.md`)
  2. Summarize what has been accomplished so far
  3. Outline what remains to be done
  4. End with a specific, clear question: "I'm approaching the token limit. Would you like me to continue with the remaining tasks in the next response?"
  5. Explicitly state: "Please note that the token limit has been reached for this response."
- When continuing from a previous token-limited response:
  1. Briefly summarize what was accomplished in the previous response
  2. Continue where the previous response left off
  3. Follow the same token limit protocol if needed again
- Prioritize completing critical or atomic tasks before reaching token limits
- Ensure all work is properly saved before ending a token-limited response

## Commit Guidelines
- Format: `type(scope): description`
- Types:
  - feat
  - fix
  - docs
  - style
  - refactor
  - test
  - chore
- Length: Keep commits semantic and concise
- Command: `git add . && git commit -m "..."` (do not push)
- Only commit if user explicitly asks for

## Testing
### Test Creation
- **Unit Tests**: 
  - Create for all new functions, methods, and components
  - Focus on testing one piece of functionality in isolation
  - Mock dependencies to ensure isolation
  - Aim for high code coverage (minimum 80%)
  - Name tests descriptively using format: `describe('function/component name', () => it('should do something specific', () => {...}))`

- **Integration Tests**:
  - Create for all critical business flows and user journeys
  - Test interaction between multiple components or services
  - Minimize mocking to test real interactions
  - Focus on data flow and state changes across components

- **UI Tests**:
  - Create for all user-facing components and pages
  - Test rendering, user interactions, and responsive design
  - Include accessibility testing
  - Verify visual consistency and user experience

### Test Execution
- **When to Run Tests**:
  - Run relevant unit tests after any code change
  - Run integration tests before committing code that affects multiple components
  - Run UI tests when making changes to user interfaces
  - Run full test suite before merging feature branches
  - Run tests in CI/CD pipeline for all pull requests

- **Test Commands**:
  - Use project-specific test commands (e.g., `npm test`, `yarn test`)
  - For focused testing, use pattern matching to run specific tests
  - Document all custom test commands in README.md

### Test Maintenance
- Keep tests up-to-date with code changes
- Refactor tests when refactoring code
- Fix failing tests before adding new features
- Document test coverage gaps and edge cases not covered
- Review and update test data regularly

### AI Agent Testing Responsibilities
- Proactively identify when tests are needed for new or modified code
- Suggest test cases based on implementation details and requirements
- Create appropriate tests for each type of functionality
- Execute relevant tests after implementing changes
- Report test results and fix any test failures
- Maintain existing tests when refactoring code
- Recommend test improvements to increase coverage and quality
